---
title: "Using an interim estimate for conditional power"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{using-interim-estimates}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(optconerrf)
```

# Introduction

In their original article on optimal conditional error functions for the control of conditional power, Brannath and Bauer primarily describe cases in which the conditional power is controlled at a fixed effect size $\Delta_1$.
However, they note that the incorporation of an interim estimate, i.e., allowing the effect size to depend on the interim data, is also possible.

# Estimating the treatment effect at interim

Given a trial with first-stage p-value $p_1$ and first-stage information $I_1$, the treatment effect on the mean difference scale can be estimated as:

$$
\hat{\Delta}_1(p_1)=\Phi^{-1}(1-p_1)/\sqrt{I_1}.
$$
A disadvantage of this estimator is the fact that it allows for very large and very small effect estimates.
In fact, if the first-stage futility boundary $\alpha_0$ of the trial exceeds 0.5, the estimated effect may even be negative.
Negative effects, which belong to the null hypothesis $H_0: \Delta \leq 0$, cannot be powered for and should therefore not be allowed.
Furthermore, it may not be feasible to consider any effects which fall below a minimally clinically relevant alternative $\Delta_{1, min}>0$.
Therefore, restricting the interim estimate by a lower boundary $\Delta_{1, min}>0$ is generally advisable and required in `optconerrf`.

On the other hand, one may also wish to deselect overly optimistic estimates by imposing an upper limit $\Delta_{1, max}$ on the interim estimate.
Using a maximum $\Delta_{1, max}$ is optional in `optconerrf`.

Applying both a lower cut-off $\Delta_{1, min}$ and an upper cut-off $\Delta_{1, max}$, a modified interim estimate is:

$$
\tilde{\Delta}_1(p_1)=\min(\max(\hat{\Delta}_1(p_1),\, \Delta_{1,min}), \, \Delta_{1, max}).
$$

This estimate can also be expressed in terms of the non-centrality parameter scale, which incorporates the first-stage information $I_1$:

$$
\tilde{\vartheta}_1(p_1) = \min(\max(\hat{\vartheta}_1(p_1),\, \vartheta_{1,min}), \, \vartheta_{1, max}),
$$
where $\hat{\vartheta}_1(p_1) = \hat{\Delta}_1(p_1)\cdot \sqrt{I_1} = \Phi^{-1}(1-p_1)$, $\vartheta_{1, min} = \Delta_{1,min}\cdot\sqrt{I_1}$ and $\vartheta_{1, max} = \Delta_{1, max} \cdot \sqrt{I_1}$.

In `optconerrf`, the restrictions on the interim estimate can be specified on both the mean difference scale and the non-centrality parameter scale (although it is not possible to mix the scales).

# Trial example

Consider an adaptive two-stage design with $\alpha = 0.025$, $\alpha_1 = 0.002$ and $\alpha_0 = 0.8$.
After observing a first-stage information $I_1=100$, a conditional power $CP=0.9$ is desired with the use of an interim estimate.
The minimally clinically relevant effect is considered to be $\Delta_{1,min}=0.1$ and effects larger than $\Delta_{1,max}=0.6$ are assumed to be of no interest.
The parameter for the calculation of the likelihood ratio is to be estimated from the interim data as well, i.e., the maximum likelihood ratio should be used.

This specification leads to a conditional error function that is increasing for some first-stage p-values $p_1$, which is automatically transformed according to the algorithm described in Brannath et al. (2024).
If the user wishes to acquire the non-monotone function instead, this can be achieved by using `enforceMonotonicity=FALSE` as an additional argument.
This is recommended only for illustration purposes.

```{r}
trialDesign <- getDesignOptimalConditionalErrorFunction(
  alpha = 0.025, alpha1 = 0.002, alpha0 = 0.8,
  conditionalPower = 0.9, useInterimEstimate = TRUE,
  firstStageInformation = 100, delta1Min = 0.1, delta1Max = 0.6,
  likelihoodRatioDistribution = "maxlr"
)
```

The resulting optimal conditional error function can be displayed using the `plot()` function.
As an additional functionality of `optconerrf`, it is also possible to plot the corresponding non-monotone function (i.e., increasing on some intervals) directly by setting `plotNonMonotoneFunction = TRUE` in the `plot()` function:

```{r, fig.dim = c(6,4), warning = FALSE}
plot(trialDesign, type = 1, plotNonMonotoneFunction = TRUE) + 
  ggplot2::ylim(c(0, 0.2))
```

Note that the y-axis is adjusted to highlight the region in which the monotonisation is performed.
The solid black line represents the non-increasing optimal conditional error function and the grey dashed line shows its non-monotone counterpart.
The interval on which the monotonisation is performed can be obtained by printing the design object or by specifically printing its field `monotonisationConstants`.

```{r}
print(trialDesign)
```

Printing the trial design only gives a brief overview over the monotonisation process, whereas printing `monotonisationConstants` field yields additional information and allows for the display of more digits.

```{r}
print(trialDesign$monotonisationConstants, digits = 10)
```

The interval is described by its lower limit `dls[1]` and its upper limit `dus[1]`.
On this interval, the function $Q(p_1)$ must be set to the constant value indicated by `qs[1]`.

Note that even though the monotone and non-monotone optimal conditional error functions are visually indistinguishable in the plot beyond this interval, they are not exactly identical because the level constants for the two cases are slightly different.

