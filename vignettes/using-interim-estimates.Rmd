---
title: "Using an interim estimate for conditional power"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{using-interim-estimates}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(optconerrf)
```

# Introduction

In their original article on optimal conditional error functions for the control of conditional power, Brannath and Bauer primarily describe cases in which the conditional power is controlled at a fixed effect size $\Delta_1$.
However, they note that the incorporation of an interim estimate, i.e., allowing the effect size to depend on the interim data, is also possible.

# Estimating the treatment effect at interim

Given a trial with first-stage p-value $p_1$ and first-stage information $I_1$, the treatment effect on the mean difference scale can be estimated as:

$$
\hat{\Delta}_1(p_1)=\Phi^{-1}(1-p_1)/\sqrt{I_1}.
$$
A disadvantage of this estimator is the fact that it allows for very large and very small effect estimates.
In fact, if the futility boundary $\alpha_0$ exceeds 0.5, the estimated effect may even be negative.
Negative effects, which belong to the null hypothesis, cannot be powered for and should therefore not be allowed.
Furthermore, it may not be feasible to consider any effects which fall below a minimally clinically relevant alternative $\Delta_{1, min}>0$.
Therefore, restricting the interim estimate by a lower boundary $\Delta_{1, min}>0$ is generally advisable and required in `optconerrf`.

On the other hand, one may also wish to deselect overly optimistic estimates by imposing an upper limit $\Delta_{1, max}$ on the interim estimate.
Using a maximum $\Delta_{1, max}$ is optional in `optconerrf`.

Applying both a lower cut-off $\Delta_{1, min}$ and an upper cut-off $\Delta_{1, max}$, a modified interim estimate is:

$$
\tilde{\Delta}_1(p_1)=\min(\max(\hat{\Delta}_1(p_1),\, \Delta_{1,min}), \, \Delta_{1, max}).
$$

This estimate can also be expressed in terms of the non-centrality parameter scale, which incorporates the first-stage information $I_1$:

$$
\tilde{\vartheta}_1(p_1) = \min(\max(\hat{\vartheta}_1(p_1),\, \vartheta_{1,min}), \, \vartheta_{1, max}),
$$
where $\hat{\vartheta}_1(p_1) = \hat{\Delta}_1(p_1)\cdot \sqrt{I_1} = \Phi^{-1}(1-p_1)$, $\vartheta_{1, min} = \Delta_{1,min}\cdot\sqrt{I_1}$ and $\vartheta_{1, max} = \Delta_{1, max} \cdot \sqrt{I_1}$.

In `optconerrf`, the restrictions on the interim estimate can be specified on both the mean difference scale and the non-centrality parameter scale (although it is not possible to mix the scales).

# Trial example

Consider an adaptive two-stage design with $\alpha = 0.025$, $\alpha_1 = 0.002$ and $\alpha_0 = 0.8$.
After observing a first-stage information $I_1=100$, a conditional power $CP=0.9$ is desired with the use of an interim estimate.
The minimally clinically relevant effect is considered to be $\Delta_{1,min}=0.1$ and effects larger than $\Delta_{1,max}=0.6$ are assumed to be of no interest.
The parameter for the calculation of the likelihood ratio is to be estimated from the interim data as well, i.e., the maximum likelihood ratio should be used.

This specification leads to a conditional error function that is increasing for some first-stage p-values $p_1$, which can be highlighted by the additional argument `enforceMonotonicity=FALSE`.

```{r}
trialDesign <- getDesignOptimalConditionalErrorFunction(
  alpha = 0.025, alpha1 = 0.002, alpha0 = 0.8,
  conditionalPower = 0.9, useInterimEstimate = TRUE,
  firstStageInformation = 100, delta1Min = 0.1, delta1Max = 0.6,
  likelihoodRatioDistribution = "maxlr",
  enforceMonotonicity = FALSE
)
```

A warning is produced since the resulting conditional error function is increasing on some intervals.
The optimal conditional error function for this trial design can be visualised by using the `plot()` function with the argument `type=1` (the default value).
Note that the limits of the y-axis are adjusted to highlight the range in which the optimal conditional error function is increasing:

```{r, fig.dim = c(6,4), warning = FALSE}
plot(trialDesign, type = 1) + 
  ggplot2::ylim(c(0, 0.2))
```

To produce a non-increasing conditional error function, the argument `enforceMonotonicity` can be set to `TRUE` (or omitted, since `TRUE` is its default value):

```{r}
trialDesignMonotone <- getDesignOptimalConditionalErrorFunction(
  alpha = 0.025, alpha1 = 0.002, alpha0 = 0.8,
  conditionalPower = 0.9, useInterimEstimate = TRUE,
  firstStageInformation = 100, delta1Min = 0.1, delta1Max = 0.6,
  likelihoodRatioDistribution = "maxlr",
  enforceMonotonicity = TRUE
)
```

Plotting the trial design again shows that the conditional error function is now non-increasing:

```{r, fig.dim = c(6,4), warning = FALSE}
plot(trialDesignMonotone, type = 1) + 
  ggplot2::ylim(c(0, 0.2))
```

As an additional functionality of `optconerrf`, it is also possible to plot the corresponding non-monotone function (i.e., increasing on some intervals) directly by setting `plotNonMonotoneFunction = TRUE` in the `plot()` function:

```{r, fig.dim = c(6,4), warning = FALSE}
plot(trialDesignMonotone, type = 1, plotNonMonotoneFunction = TRUE) + 
  ggplot2::ylim(c(0, 0.2))
```

The solid black line represents the non-increasing optimal conditional error function and the grey dashed line shows its non-monotone counterpart.
The interval on which the monotonisation is performed can be obtained by printing the design object or by specifically printing its field `monotonisationConstants`.

```{r}
print(trialDesignMonotone)
```

Printing the trial design only gives a brief overview over the monotonisation process, whereas printing `monotonisationConstants` field yields additional information and allows for the display of more digits.

```{r}
print(trialDesignMonotone$monotonisationConstants, digits = 10)
```

The interval is described by its lower limit `dls[1]` and its upper limit `dus[1]`.
On this interval, the function $Q(p_1)$ must be set to the constant value indicated by `qs[1]`.

Note that even though the monotone and non-monotone optimal conditional error functions are visually indistinguishable in the plot beyond this interval, they are not exactly identical.
This is because the level constants for the two cases are slightly different, as can be seen by printing them with additional digits:

```{r}
print(trialDesign$levelConstant, digits = 10)
print(trialDesignMonotone$levelConstant, digits = 10)
```

